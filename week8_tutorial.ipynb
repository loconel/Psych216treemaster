{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Psych 216A Week 8 Tutorial: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will cover classification based on logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name design",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7f70b557b8f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Louis\\Anaconda2\\lib\\site-packages\\moss\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstatistical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdesign\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmosaic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name design"
     ]
    }
   ],
   "source": [
    "import moss\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "colors = seaborn.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate two random predictors\n",
    "X = randn(100, 2)\n",
    "# Create y as a weighted sum of the 2 predictors and noise\n",
    "noise = randn(100)\n",
    "y = 0.7 * X[:, 0] + 0.5 * X[:, 1] + noise\n",
    "# Threshold y so that it is a binary classification.  Let's pretend this is\n",
    "# medical data and 0 means the patient died and 1 means the patient lived.\n",
    "# x1 and x2 are measures of symptoms\n",
    "y = (y > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the symptoms x1 and x2 for the patients who lived and died.  Notice\n",
    "that outcomes can not be perfectly classified based on x1 and x2.  This\n",
    "is due to the noise we added.  Without noise we would could classify\n",
    "perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(X[y == 0, 0], X[y == 0, 1], \"o\", label=\"dead\")\n",
    "plot(X[y == 1, 0], X[y == 1, 1], \"o\", color=colors[2], label=\"alive\")\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a logistic regression to try to classify patients who die\n",
    "or live based on their symptoms. We will use the scikit-learn package,\n",
    "which provides a nice interface for logistic regression (and many other\n",
    "statistical learning models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression().fit(X, y)\n",
    "\n",
    "# We can call the predict() method of the model to get estimated values\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# To be closer to the matlab tutorial, you can also use the predict_proba() method\n",
    "# to return probabilistc estimates in favor of each class\n",
    "y_hat2 = argmax(model.predict_proba(X), axis=1)\n",
    "\n",
    "assert all(y_hat == y_hat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a figure showing the correct and incorrect classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_c = logical_and(y == 1, y_hat == 1)\n",
    "a_i = logical_and(y == 1, y_hat == 0)\n",
    "d_c = logical_and(y == 0, y_hat == 0)\n",
    "d_i = logical_and(y == 0, y_hat == 1)\n",
    "plot(X[d_c, 0], X[d_c, 1], \"o\", color=colors[0], label=\"dead +\")\n",
    "plot(X[d_i, 0], X[d_i, 1], \"o\", color=colors[0], alpha=0.7, label=\"dead -\")\n",
    "plot(X[a_c, 0], X[a_c, 1], \"o\", color=colors[2], label=\"alive +\")\n",
    "plot(X[a_i, 0], X[a_i, 1], \"o\", color=colors[2], alpha=0.7, label=\"alive -\")\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing classification model accuracy with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like regression models, classification models can suffer from over\n",
    "fitting.  When choosing parameters to include in the model cross\n",
    "validation is the best method to determine which parameters are essential\n",
    "for a robust classification model.  However rather than R2 we will use\n",
    "percent correct as our measure of accuracy.\n",
    "\n",
    "Let's pretend we collected 2 independent data sets on the above\n",
    "experiment where we are trying to predict whether patients live or die as\n",
    "a function of their symptoms.  We will fit our classification model on\n",
    "the first data set and assess how well the model cross validates to the\n",
    "second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to generate fake data\n",
    "def make_dataset():\n",
    "    X = randn(100, 2)\n",
    "    noise = randn(100)\n",
    "    y = 0.7 * X[:, 0] + 0.5 * X[:, 1] + noise\n",
    "    y = (y > 0).astype(int)\n",
    "    return X, y\n",
    "\n",
    "# Make two datasets as above\n",
    "X1, y1 = make_dataset()\n",
    "X2, y2 = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the linear model\n",
    "line = LogisticRegression().fit(X1, y1)\n",
    "# Add additional columns where the predictors are squared\n",
    "X1_quad = hstack((X, X ** 2))\n",
    "from sklearn.preprocessing import scale\n",
    "X1_quad = scale(X1_quad)\n",
    "\n",
    "# Predict with the line and quad models\n",
    "line_model = LogisticRegression().fit(X1, y1)\n",
    "yhat_line1 = line_model.predict(X1)\n",
    "quad_model = LogisticRegression().fit(X1_quad, y1)\n",
    "yhat_quad1 = quad_model.predict(X1_quad)\n",
    "\n",
    "# Plot the models and estimates\n",
    "figure(figsize=(12, 5))\n",
    "# Plot the actual classes of Y1\n",
    "subplot(121)\n",
    "plot(X1[y1==0, 0], X1[y1==0, 1], \"o\", color=colors[0], markersize=15)\n",
    "plot(X1[y1==1, 0], X1[y1==1, 1], \"o\", color=colors[2], markersize=15)\n",
    "\n",
    "# Plot the predicted classs from the linear model\n",
    "plot(X1[yhat_line1==0, 0], X1[yhat_line1==0, 1], \"o\", color=colors[0], markersize=7)\n",
    "plot(X1[yhat_line1==1, 0], X1[yhat_line1==1, 1], \"o\", color=colors[2], markersize=7)\n",
    "\n",
    "# Now do the same for the quadratic model\n",
    "subplot(122)\n",
    "plot(X1[y1==0, 0], X1[y1==0, 1], \"o\", color=colors[0], markersize=15)\n",
    "plot(X1[y1==1, 0], X1[y1==1, 1], \"o\", color=colors[2], markersize=15)\n",
    "\n",
    "# Plot the predicted classs from the linear model\n",
    "plot(X1[yhat_quad1==0, 0], X1[yhat_quad1==0, 1], \"o\", color=colors[0], markersize=7)\n",
    "plot(X1[yhat_quad1==1, 0], X1[yhat_quad1==1, 1], \"o\", color=colors[2], markersize=7)\n",
    "\n",
    "# Compute the accuracy for each model\n",
    "acc_line = line_model.score(X1, y1)\n",
    "acc_quad = quad_model.score(X1_quad, y1)\n",
    "print \"Linear: %.2f\" % acc_line\n",
    "print \"Quadratic: %.2f\" % acc_quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asses how well each model classifies the new dataset (cross validation).\n",
    "To do this apply the model estimated on dataset 1 to the predictors and\n",
    "outputs from dataset 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_cv_acc = line_model.score(X2, y2)\n",
    "X2_quad = scale(hstack((X2, X2 ** 2)))\n",
    "quad_cv_acc = quad_model.score(X2_quad, y2)\n",
    "print \"Linear model cross-validated accuracy: %.2f\" % line_cv_acc\n",
    "print \"Quadratic model cross-validated accuracy: %.2f\" % quad_cv_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
